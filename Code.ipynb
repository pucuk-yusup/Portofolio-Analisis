{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BN8oyF8v6Ks"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def describe_dataset(csv_file):\n",
        "    # Load the dataset\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Get number of rows and columns\n",
        "    num_rows, num_columns = df.shape\n",
        "\n",
        "    # Get column names\n",
        "    column_names = df.columns.tolist()\n",
        "\n",
        "    # Print dataset description\n",
        "    print(f\"Dataset: {csv_file}\")\n",
        "    print(f\"Number of rows: {num_rows}\")\n",
        "    print(f\"Number of columns: {num_columns}\")\n",
        "    print(\"Column names:\")\n",
        "    for idx, name in enumerate(column_names, start=1):\n",
        "        print(f\"{idx}. {name}\")\n",
        "\n",
        "\n",
        "# Example usage\n",
        "csv_file = \"/content/nama.csv\"  # Replace with your CSV file path\n",
        "describe_dataset(csv_file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def null_percentage(csv_file):\n",
        "    # Load the dataset\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Calculate percentage of null values for each column\n",
        "    null_percent = (df.isnull().sum() / len(df)) * 100\n",
        "\n",
        "    # Print percentage of null values per column\n",
        "    print(f\"Dataset: {csv_file}\")\n",
        "    print(\"Percentage of null values per column:\")\n",
        "    for column, percent in null_percent.items():\n",
        "        print(f\"{column}: {percent:.2f}%\")\n",
        "\n",
        "# Example usage\n",
        "csv_file = \"/content/nama.csv\"  # Replace with your CSV file path\n",
        "null_percentage(csv_file)"
      ],
      "metadata": {
        "id": "gwsGucavykCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_duplicates(csv_file, id_column):\n",
        "    # Load the dataset\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Find duplicate rows based on all columns\n",
        "    duplicates = df[df.duplicated(keep=False)]\n",
        "\n",
        "    # Print duplicate rows with ID\n",
        "    if not duplicates.empty:\n",
        "        print(f\"Dataset: {csv_file}\")\n",
        "        print(\"Duplicate rows found:\")\n",
        "        print(duplicates[[id_column] + list(df.columns[df.columns != id_column])])\n",
        "    else:\n",
        "        print(\"No duplicate rows found.\")\n",
        "\n",
        "# Example usage\n",
        "csv_file = \"/content/nama.csv\"  # Replace with your CSV file path\n",
        "id_column = \"Transaction ID\"  # Replace with the ID column name\n",
        "find_duplicates(csv_file, id_column)"
      ],
      "metadata": {
        "id": "BG4aE2MRNCz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identify_outliers(csv_file, column):\n",
        "    # Load the dataset\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Calculate Q1, Q3, and IQR\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    # Define lower and upper bounds\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Identify outliers\n",
        "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Dataset: {csv_file}\")\n",
        "    print(f\"Column: {column}\")\n",
        "    print(f\"Lower Bound: {lower_bound}\")\n",
        "    print(f\"Upper Bound: {upper_bound}\")\n",
        "    print(\"Outliers:\")\n",
        "    print(outliers)\n",
        "\n",
        "# Example usage\n",
        "csv_file = \"/content/nama.csv\"  # Replace with your CSV file path\n",
        "column = \"Total_Revenue\"  # Replace with the column name to analyze\n",
        "identify_outliers(csv_file, column)"
      ],
      "metadata": {
        "id": "TMz40BS2JDBX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}